package com.xingray.java.openai.webflux.entity;

import com.fasterxml.jackson.annotation.JsonProperty;
import com.xingray.java.openai.webflux.entity.Message;

import java.util.List;
import java.util.Map;

public class ChatRequest {
    /**
     * model
     * string
     * Required
     * ID of the model to use. Currently, only gpt-3.5-turbo and gpt-3.5-turbo-0301 are supported.
     */
    @JsonProperty("model")
    private String model;

    /**
     * messages
     * array
     * Required
     * The messages to generate chat completions for, in the chat format.
     */
    @JsonProperty("messages")
    private List<Message> messages;

    /**
     * temperature
     * number
     * Optional
     * Defaults to 1
     * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
     * <p>
     * We generally recommend altering this or top_p but not both.
     */
    @JsonProperty("temperature")
    private Double temperature;

    /**
     * top_p
     * number
     * Optional
     * Defaults to 1
     * An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
     * <p>
     * We generally recommend altering this or temperature but not both.
     */
    @JsonProperty("top_p")
    private Double topP;

    /**
     * n
     * integer
     * Optional
     * Defaults to 1
     * How many chat completion choices to generate for each input message.
     */
    @JsonProperty("n")
    private Integer n;

    /**
     * stream
     * boolean
     * Optional
     * Defaults to false
     * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message.
     */
    @JsonProperty("stream")
    private Boolean stream;

    /**
     * stop
     * string or array
     * Optional
     * Defaults to null
     * Up to 4 sequences where the API will stop generating further tokens.
     */
    @JsonProperty("stop")
    private List<String> stop;

    /**
     * max_tokens
     * integer
     * Optional
     * Defaults to inf
     * The maximum number of tokens allowed for the generated answer. By default, the number of tokens the model can return will be (4096 - prompt tokens).
     */
    @JsonProperty("max_tokens")
    private Integer maxTokens;

    /**
     * presence_penalty
     * number
     * Optional
     * Defaults to 0
     * Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
     * <p>
     * See more information about frequency and presence penalties.
     */
    @JsonProperty("presence_penalty")
    private Double presence_penalty;

    /**
     * frequency_penalty
     * number
     * Optional
     * Defaults to 0
     * Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
     * <p>
     * See more information about frequency and presence penalties.
     */
    @JsonProperty("frequency_penalty")
    private Double frequencyPenalty;

    /**
     * logit_bias
     * map
     * Optional
     * Defaults to null
     * Modify the likelihood of specified tokens appearing in the completion.
     * Accepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
     */
    @JsonProperty("logit_bias")
    private Map<String, String> logitBias;

    /**
     * user
     * string
     * Optional
     * A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. Learn more.
     */
    @JsonProperty("user")
    private String user;

    public String getModel() {
        return model;
    }

    public void setModel(String model) {
        this.model = model;
    }

    public List<Message> getMessages() {
        return messages;
    }

    public void setMessages(List<Message> messages) {
        this.messages = messages;
    }

    public Double getTemperature() {
        return temperature;
    }

    public void setTemperature(Double temperature) {
        this.temperature = temperature;
    }

    public Double getTopP() {
        return topP;
    }

    public void setTopP(Double topP) {
        this.topP = topP;
    }

    public Integer getN() {
        return n;
    }

    public void setN(Integer n) {
        this.n = n;
    }

    public Boolean getStream() {
        return stream;
    }

    public void setStream(Boolean stream) {
        this.stream = stream;
    }

    public List<String> getStop() {
        return stop;
    }

    public void setStop(List<String> stop) {
        this.stop = stop;
    }

    public Integer getMaxTokens() {
        return maxTokens;
    }

    public void setMaxTokens(Integer maxTokens) {
        this.maxTokens = maxTokens;
    }

    public Double getPresence_penalty() {
        return presence_penalty;
    }

    public void setPresence_penalty(Double presence_penalty) {
        this.presence_penalty = presence_penalty;
    }

    public Double getFrequencyPenalty() {
        return frequencyPenalty;
    }

    public void setFrequencyPenalty(Double frequencyPenalty) {
        this.frequencyPenalty = frequencyPenalty;
    }

    public Map<String, String> getLogitBias() {
        return logitBias;
    }

    public void setLogitBias(Map<String, String> logitBias) {
        this.logitBias = logitBias;
    }

    public String getUser() {
        return user;
    }

    public void setUser(String user) {
        this.user = user;
    }

    @Override
    public String toString() {
        return "ChatRequest{" +
                "model='" + model + '\'' +
                ", messages=" + messages +
                ", temperature=" + temperature +
                ", topP=" + topP +
                ", n=" + n +
                ", stream=" + stream +
                ", stop=" + stop +
                ", maxTokens=" + maxTokens +
                ", presence_penalty=" + presence_penalty +
                ", frequencyPenalty=" + frequencyPenalty +
                ", logitBias=" + logitBias +
                ", user='" + user + '\'' +
                '}';
    }
}
